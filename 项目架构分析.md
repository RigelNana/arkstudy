# ArkStudy 项目架构分析

## 1. 高级架构概述

ArkStudy 是一个云原生、基于微服务架构的智能化学习平台。项目旨在通过整合多模态学习资料（文档、音视频等），利用大语言模型（LLM）和人工智能技术，提供智能问答、自动化出题和个性化学习分析等核心功能。

其架构设计遵循**关注点分离 (Separation of Concerns)** 和**云原生 (Cloud-Native)** 的核心原则，具备高内聚、低耦合、可伸缩和可观测的特点。

### 1.1 核心技术栈

- **后端语言**: **Go** (用于构建高性能的基础微服务) & **Python** (用于实现复杂的 AI/LLM 相关逻辑)。
- **服务间通信**:
    - **gRPC**: 作为服务间同步调用的主要协议，通过 Protobuf 定义标准化的接口，实现高效的二进制传输。
    - **Kafka**: 作为异步消息总线，用于解耦耗时的数据处理任务（如文件转码、OCR、向量化），提升系统的响应能力和弹性。
- **数据存储**:
    - **PostgreSQL + pgvector**: 作为主数据库，不仅存储业务元数据，还利用 `pgvector` 扩展进行高效的向量相似度检索，是 RAG (Retrieval-Augmented Generation) 功能的核心。
    - **MinIO**: S3 兼容的对象存储，用于存放用户上传的原始学习资料文件。
    - **Redis**: 用于缓存热点数据和用户会话，降低数据库负载。
- **部署与运维**:
    - **容器化**: 所有服务均被打包为 **Docker** 镜像。
    - **容器编排**: **Kubernetes** 作为应用的运行时环境，通过 **Helm Chart** 进行声明式的部署和配置管理。
    - **CI/CD**: **GitLab CI/CD** 自动化了从代码提交到镜像构建、再到 Kubernetes 部署的全过程。
- **可观测性**: 通过 **Prometheus** 收集关键性能指标，为监控和告警提供数据支持。

### 1.2 架构风格

ArkStudy 采用了混合架构模式：

1.  **面向服务的微服务架构**: 将系统按业务能力垂直拆分为一系列独立的服务（如用户、认证、资料、测验等），每个服务都有清晰的职责边界。
2.  **事件驱动架构**: 对于学习资料的处理，采用了事件驱动模式。文件上传后，`material-service` 会发布一个事件到 Kafka，下游的 `ocr-service` 和 `llm-service` 会订阅该事件并进行异步处理，实现了生产者与消费者的解耦。

## 2. 微服务详解

### 2.1 API Gateway (`gateway/`)

- **职责**: 系统的统一入口 (Single Point of Entry)，扮演“门面”角色。
- **功能**:
    - **请求路由**: 基于 Gin 框架，根据 URL 路径将外部 HTTP 请求路由到相应的内部 gRPC 服务。
    - **协议转换**: 将客户端的 HTTP/JSON 请求转换为后端服务能够理解的 gRPC/Protobuf 格式。
    - **认证与授权**: 通过 JWT 中间件，对受保护的路由进行统一的身份验证，解析 Token 并将用户信息（如 `user_id`）注入请求上下文。
    - **API 文档**: 集成 OpenAPI (Swagger)，提供在线的 API 文档和测试界面。
- **技术实现**: Go, Gin Web Framework。

### 2.2 用户服务 (`services/user-service/`)

- **职责**: 用户身份信息的权威源 (Source of Truth)。
- **功能**:
    - **用户管理**: 提供用户的 CRUD (创建、读取、更新、删除) gRPC 接口。
    - **信息查询**: 支持通过用户 ID、用户名、邮箱等多种方式查询用户基本信息。
- **定位**: 基础数据服务，被 `auth-service` 等多个上层服务依赖。

### 2.3 认证服务 (`services/auth-service/`)

- **职责**: 系统的“门禁”，负责用户的认证凭证管理。
- **功能**:
    - **用户注册**: 在 `user-service` 创建用户实体后，为该用户创建认证记录（存储密码哈希）。
    - **用户登录**: 验证用户凭证，成功后生成 JWT (JSON Web Token) 并返回给 API Gateway。
    - **Token 验证**: 提供 gRPC 接口供 API Gateway 验证 Token 的有效性。
- **服务交互**: 在注册流程中，会通过 gRPC **同步调用** `user-service`，确保认证信息与用户信息的一致性。

### 2.4 学习资料服务 (`services/material-service/`)

- **职责**: 学习资料的“仓储管理员”，负责资料的生命周期和处理流程的编排。
- **功能**:
    - **文件上传**: 处理用户上传的文件，将文件本身存入 MinIO 对象存储，并将文件的元数据（文件名、类型、上传者等）写入 PostgreSQL。
    - **任务分发**: 文件上传成功后，作为**生产者 (Producer)**，向 Kafka 的 `file_processing` 主题发送一条消息，触发下游的异步处理流程。
    - **状态追踪**: 维护一个 `processing_results` 表，用于追踪异步任务（如 OCR、向量化）的执行状态。`ocr-service` 等处理服务完成后会回调该服务更新状态。

### 2.5 OCR 服务 (`services/ocr-service/`)

- **职责**: 提供光学字符识别 (OCR) 能力的专用 AI 服务。
- **功能**:
    - **异步消费**: 作为 **消费者 (Consumer)**，监听 Kafka 中特定主题的消息。
    - **文本提取**: 从消息中获取文件 URL，从 MinIO 下载文件，并使用 OCR 引擎提取其中的文本内容。
    - **结果回调**: OCR 处理完成后，通过 gRPC **同步调用** `material-service` 的接口，将提取的文本内容和最终状态写回数据库。
- **技术实现**: Go, Segmentio Kafka Client。

### 2.6 LLM 服务 (`services/llm-service/`)

- **职责**: 系统的“AI 大脑”，封装了所有与大语言模型和向量检索相关的核心能力。
- **功能**:
    - **混合服务模式**: 同时提供 gRPC (对内) 和 FastAPI HTTP (对管理/调试) 两种接口。
    - **异步文档处理**: 监听 Kafka 消息，触发完整的文档处理流水线：
        1.  **智能分块**: 识别文档结构，进行语义相关的文本分块。
        2.  **向量化**: 调用嵌入模型 (Embedding Model) 将文本块转换为向量。
        3.  **数据持久化**: 将文本块、元数据和向量存入 `pg_vector` 数据库。
    - **RAG 核心能力**:
        - **语义检索**: 提供 gRPC 接口，根据查询语句从向量数据库中检索最相关的文本片段。
        - **问答生成**: 结合检索到的上下文和用户问题，调用 LLM 生成答案，支持流式返回。
- **技术实现**: Python, FastAPI, `asyncio`, AIOKafka。

- **高级功能：对话式 RAG (Conversational RAG)**:
    - **自动向量化**: 在非流式问答 (`/api/ai/ask`) 的调用链路中，系统会尝试将当前对话的问答轮次（用户问题和模型回答）进行向量化，并存入向量数据库。这些对话记录以 `session:<session_id>` 的形式作为其 `material_id`。
    - **功能目标**: 此机制旨在实现“对话记忆”，让模型在后续的对话中能够检索到之前的交流内容，从而更好地理解上下文。
    - **当前局限**:
        1.  **实现不一致**: 流式接口 (`/api/ai/ask/stream`) 当前**未实现**此自动向量化逻辑。
        2.  **检索未优化**: 语义检索的 SQL 查询逻辑目前未对 `session:*` 类型的材料做特殊处理或加权，对话历史的检索效果可能受限。

### 2.7 测验服务 (`services/quiz-service/`)

- **职责**: “智能出题与评估引擎”，连接学习内容与效果检验。
- **功能**:
    - **AI 能力编排**: 作为一个**协调者 (Orchestrator)**，它不直接执行 AI 计算，而是按特定业务逻辑调用 `llm-service` 提供的原子能力。
    - **智能出题**:
        1.  调用 `llm-service` 的语义检索功能，获取与学习资料相关的内容。
        2.  调用 `llm-service` 自动提取核心知识点。
        3.  动态构建详细的 Prompt，调用 `llm-service` 生成符合要求的题目。
    - **主观题评估**: 对于简答题等，将题目、标准答案和用户答案一同发送给 `llm-service` 进行自动评分。
- **容错设计**: 当 `llm-service` 调用失败时，具备回退到直接调用外部 OpenAI API 的能力，增强了系统健壮性。

## 3. 服务间通信 (`proto/`)

- **机制**: 项目统一使用 **Protobuf** 来定义服务的数据结构 (Messages) 和接口 (Services)。这种方式提供了强类型约束、向后兼容性和高效的二进制序列化能力。
- **同步调用**: 服务间的同步请求采用 **gRPC**。这为内部通信提供了高性能、低延迟的 RPC 调用。
- **异步通信**: 耗时的数据处理任务通过 **Kafka** 消息队列进行解耦。生产者服务（如 `material-service`）发布消息，一个或多个消费者服务（如 `ocr-service`, `llm-service`）订阅并处理这些消息。
- **代码生成**: `proto/` 目录存放所有 `.proto` 定义文件，并通过 `protoc` 编译器为 Go 和 Python 生成相应的客户端和服务端代码，确保了跨语言调用的类型安全。

## 4. 部署与运维 (DevOps)

### 4.1 CI/CD 流水线

项目采用 **GitLab CI/CD** 实现了高度自动化的持续集成与持续部署流程，定义在 [`.gitlab-ci.yml`](.gitlab-ci.yml) 文件中。关键阶段包括：

1.  **Lint**: 对 Go 和 Python 代码进行静态检查和格式化，确保代码质量。
2.  **Build**: 编译 Go 代码，确保项目可以成功构建。
3.  **Docker**:
    - 使用 **Kaniko** 在 GitLab Runner 中安全地构建 Docker 镜像，无需特权容器。
    - 为每个微服务（`gateway`, `auth-service` 等）构建独立的镜像。
    - 将构建好的镜像推送到 Docker Registry，并使用 Git Commit SHA 作为标签，保证了镜像的可追溯性。
4.  **Validate**: 在部署前，使用 `helm lint` 和 `helm template` 命令验证 Helm Chart 的语法和模板渲染是否正确，提前发现配置错误。
5.  **Deploy**:
    - 这是一个**手动触发**的阶段，通常在合并到 `main` 分支后进行。
    - 使用 `helm upgrade --install` 命令，将应用以声明式的方式部署或更新到目标 Kubernetes 集群。
    - 通过不同的 `values` 文件（如 `values-dev.yaml`）来管理不同环境的配置。

### 4.2 容器化与 Kubernetes 部署

- **容器化**: 每个服务目录下都有一个 [`Dockerfile`](services/auth-service/Dockerfile)，遵循多阶段构建 (multi-stage build) 的最佳实践，以生成最小化的生产镜像。
- **部署管理**:
    - **Helm**: 作为首选的 Kubernetes 包管理工具。项目提供了一个通用的**“元”Chart** (`deploy/helm/arkstudy`)，能够通过 `values.yaml` 文件灵活地部署全部或部分微服务。
    - **配置即代码**: `values.yaml` 文件是部署的“单一事实来源”，定义了服务的副本数、镜像版本、环境变量、资源限制、健康检查等所有部署细节。
    - **服务发现**: 在 Kubernetes 集群内部，服务之间通过标准的 DNS 名称 (`<service-name>.<namespace>`) 进行发现和通信，无需硬编码 IP 地址。
- **数据库初始化**: [`init.sql`](init.sql) 文件通过 ConfigMap 挂载到 PostgreSQL Pod 中，在数据库首次启动时自动执行，完成表结构的创建。

## 5. 总结

ArkStudy 是一个功能完善、架构清晰的现代化云原生应用。它通过精心设计的微服务、混合通信模式（gRPC + Kafka）以及高度自动化的 DevOps 流程，构建了一个健壮、可扩展且易于维护的智能化学习平台。

## 6. 架构改进计划

### 6.1 [P0] 完善 Prometheus 监控覆盖

**目标**: 确保所有服务（特别是 `llm-service`）的 HTTP 和 gRPC 指标都能被 Prometheus 采集。

**`llm-service` 变更详情**:

1.  **添加依赖**:
    -   在 `services/llm-service/requirements.txt` 文件中添加 `py-grpc-prometheus>=0.8.0`。

2.  **代码修改 (`services/llm-service/app/main.py`)**:
    -   **取消注释**:
        -   取消 `from prometheus_fastapi_instrumentator import Instrumentator` 的注释。
    -   **添加导入**:
        -   导入 `from py_grpc_prometheus.aio.prometheus_aio_server_interceptor import PrometheusAioServerInterceptor`。
    -   **修改 `on_startup` 函数**:
        -   在 `on_startup` 函数的开头，添加 FastAPI 的监控初始化：
            ```python
            instrumentator = Instrumentator().instrument(app)
            instrumentator.expose(app)
            ```
    -   **修改 gRPC 服务器创建逻辑**:
        -   在 `server = grpc.aio.server()` 之后，添加拦截器：
            ```python
            server = grpc.aio.server(interceptors=[PrometheusAioServerInterceptor()])
            ```